{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/arash/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/arash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk # Import the NLTK library\n",
    "\n",
    "# Download the necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "متن: I love this movie!\n",
      "توکن‌ها: ['I', 'love', 'this', 'movie', '!']\n",
      "کلمات غیر مفید (stopwords): {'yourself', 'no', 'herself', 'isn', 'above', 'couldn', \"we'd\", 'some', 'it', 'was', 'nor', 'few', 'each', 're', 'before', 'yourselves', 'an', 'after', \"you'd\", 'where', 'during', 's', \"hasn't\", 'our', 'i', 'while', \"they've\", 'd', 'have', 'such', 'their', 'am', \"it'll\", 'you', \"should've\", 'did', 'didn', 'between', 'do', \"couldn't\", 'which', 'me', 'y', 'any', 'themselves', 'were', 'those', 'through', 'theirs', 'up', 'to', 'myself', \"she'll\", 'hers', \"weren't\", 'he', 'down', 'been', 'who', 'be', 'we', 'not', 'weren', 'aren', 'from', \"hadn't\", 'him', 'she', 'the', 'then', 'don', 'being', 'both', 'mustn', \"didn't\", 'just', 'hasn', 'how', 've', \"aren't\", 'most', \"we'll\", \"needn't\", 'more', 'shouldn', \"wasn't\", 'a', \"mustn't\", 'off', 'or', 'ours', \"they'll\", \"he'll\", \"i'm\", 'haven', \"we're\", 'mightn', \"she's\", 'having', 'as', 'own', \"you'll\", 'against', 'doing', \"don't\", \"it's\", 'until', 'his', 'all', 'in', 'has', \"i've\", 'there', 'for', 'shan', 'by', 'further', 'its', 'is', 'only', 'why', \"that'll\", 'here', 'hadn', 'too', 'can', 'doesn', 'yours', 'll', 'itself', 'with', \"i'd\", 't', 'and', 'my', 'needn', 'into', 'himself', 'once', \"he's\", 'will', 'if', 'had', 'should', 'than', \"haven't\", 'won', 'these', 'under', 'this', 'but', 'when', 'about', \"isn't\", \"it'd\", 'her', 'o', 'on', 'again', 'what', \"wouldn't\", \"doesn't\", \"you've\", 'wasn', 'that', 'them', 'out', \"she'd\", \"they're\", 'wouldn', 'other', 'are', \"shan't\", 'whom', 'm', 'because', 'now', 'so', \"they'd\", 'very', 'at', 'ain', 'ourselves', \"mightn't\", \"shouldn't\", \"won't\", 'does', \"we've\", 'of', \"i'll\", 'same', 'they', 'ma', 'over', 'below', \"he'd\", \"you're\", 'your'}\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Create a DataFrame with some sample data\n",
    "data = {\"review\": [\"I love this movie!\", \"This is a bad movie.\", \"It was an okay movie, not the best.\", \"Absolutely fantastic movie!\"]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Checking how tokenizer and stopwords work\n",
    "text = df[\"review\"][0]\n",
    "tokens = word_tokenize(text)  # tokenizing\n",
    "stop_words = set(stopwords.words('english'))  # loading the stopwords\n",
    "\n",
    "print(\"متن:\", text)\n",
    "print(\"توکن‌ها:\", tokens)\n",
    "print(\"کلمات غیر مفید (stopwords):\", stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punkt موجود است: /home/arash/nltk_data/tokenizers/punkt\n",
      "stopwords موجود است: /home/arash/nltk_data/corpora/stopwords\n"
     ]
    }
   ],
   "source": [
    "# Check if the necessary NLTK data is available if encountered any error\n",
    "print(\"punkt موجود است:\", nltk.data.find('tokenizers/punkt'))\n",
    "print(\"stopwords موجود است:\", nltk.data.find('corpora/stopwords'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                review              cleaned_review\n",
      "0                   I love this movie!                  love movie\n",
      "1                 This is a bad movie.                   bad movie\n",
      "2  It was an okay movie, not the best.             okay movie best\n",
      "3          Absolutely fantastic movie!  absolutely fantastic movie\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import string\n",
    "\n",
    "# Function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        text = text.lower()  # Convert text to lowercase\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Remove punctuation\n",
    "        tokens = word_tokenize(text)  # Tokenize the text\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "        return \" \".join(tokens)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocess_text: {e}\")\n",
    "        return text  # Return the original text if an error occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                review              cleaned_review\n",
      "0                   I love this movie!                  love movie\n",
      "1                 This is a bad movie.                   bad movie\n",
      "2  It was an okay movie, not the best.             okay movie best\n",
      "3          Absolutely fantastic movie!  absolutely fantastic movie\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with some sample data\n",
    "data = {\"review\": [\"I love this movie!\", \"This is a bad movie.\", \"It was an okay movie, not the best.\", \"Absolutely fantastic movie!\"]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Execute the preprocess_text function on all the reviews\n",
    "df[\"cleaned_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "\n",
    "# Print the DataFrame first 5 rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"review\"].astype(str) # Convert the \"review\" column to string type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     I love this movie!\n",
       "1                   This is a bad movie.\n",
       "2    It was an okay movie, not the best.\n",
       "3            Absolutely fantastic movie!\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"] # Display the \"review\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
